# Core dependencies
torch>=2.1.0
transformers>=4.35.0
tokenizers>=0.15.0
datasets>=2.14.0
accelerate>=0.24.0
bitsandbytes>=0.41.0

# Training and optimization
wandb>=0.16.0
tensorboard>=2.15.0
deepspeed>=0.12.0
flash-attn>=2.3.0

# Data processing
numpy>=1.24.0
pandas>=2.0.0
scipy>=1.11.0
scikit-learn>=1.3.0

# Utilities
tqdm>=4.66.0
pyyaml>=6.0
click>=8.1.0
rich>=13.0.0
matplotlib>=3.7.0
seaborn>=0.12.0

# Development
jupyter>=1.0.0
ipywidgets>=8.1.0
black>=23.0.0
flake8>=6.0.0
pytest>=7.4.0

# Optional: For advanced features
triton>=2.1.0  # For custom kernels
xformers>=0.0.22  # Memory efficient attention
peft>=0.6.0  # Parameter efficient fine-tuning
evaluate>=0.4.0  # Model evaluation metrics
